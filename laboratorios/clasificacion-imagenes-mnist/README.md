# ğŸ”¬ Laboratorio: ClasificaciÃ³n de ImÃ¡genes con MNIST

## ğŸ“‹ DescripciÃ³n

Este laboratorio te guÃ­a en la construcciÃ³n de un clasificador de dÃ­gitos escritos a mano usando el famoso dataset MNIST y una red neuronal convolucional (CNN) en PyTorch.

**Nivel**: ğŸŸ¢ BÃ¡sico

## ğŸ¯ Objetivos

- Cargar y explorar el dataset MNIST
- Implementar una CNN desde cero en PyTorch
- Entrenar el modelo con tÃ©cnicas de optimizaciÃ³n
- Evaluar el rendimiento del modelo
- Visualizar predicciones y errores
- Guardar y cargar modelos entrenados

## ğŸ”§ Requisitos

### Software
- Python 3.8+
- PyTorch 2.0+
- torchvision
- matplotlib
- numpy
- tqdm

### Hardware
- CPU: Suficiente para este proyecto (entrenamiento ~5-10 min)
- GPU (opcional): Acelera el entrenamiento (~1-2 min)

### Conocimientos Previos
- Conceptos bÃ¡sicos de PyTorch
- Redes neuronales bÃ¡sicas
- Python y programaciÃ³n orientada a objetos

## ğŸ“Š Dataset

**MNIST** (Modified National Institute of Standards and Technology)
- 60,000 imÃ¡genes de entrenamiento
- 10,000 imÃ¡genes de prueba
- ImÃ¡genes en escala de grises 28x28 pÃ­xeles
- 10 clases (dÃ­gitos 0-9)

El dataset se descargarÃ¡ automÃ¡ticamente la primera vez que ejecutes el cÃ³digo.

## ğŸ“ Estructura del Proyecto

```
clasificacion-imagenes-mnist/
â”œâ”€â”€ README.md                    # Este archivo
â”œâ”€â”€ requirements.txt             # Dependencias especÃ­ficas
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01-exploracion.ipynb    # ExploraciÃ³n del dataset
â”‚   â”œâ”€â”€ 02-modelo.ipynb         # ConstrucciÃ³n y entrenamiento
â”‚   â””â”€â”€ 03-evaluacion.ipynb     # EvaluaciÃ³n y visualizaciÃ³n
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model.py                # DefiniciÃ³n del modelo CNN
â”‚   â”œâ”€â”€ train.py                # Script de entrenamiento
â”‚   â”œâ”€â”€ evaluate.py             # Script de evaluaciÃ³n
â”‚   â””â”€â”€ utils.py                # Funciones auxiliares
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml             # ConfiguraciÃ³n de hiperparÃ¡metros
â””â”€â”€ data/                       # Dataset (se descarga automÃ¡ticamente)
```

## ğŸš€ GuÃ­a de Uso

### 1. InstalaciÃ³n

```bash
cd laboratorios/clasificacion-imagenes-mnist
pip install -r requirements.txt
```

### 2. ExploraciÃ³n (Notebook 1)

Abre y ejecuta `notebooks/01-exploracion.ipynb`:
- Visualiza imÃ¡genes del dataset
- Analiza la distribuciÃ³n de clases
- Comprende el formato de los datos

### 3. Entrenamiento (Notebook 2)

Abre y ejecuta `notebooks/02-modelo.ipynb`:
- Define la arquitectura CNN
- Configura el optimizador y funciÃ³n de pÃ©rdida
- Entrena el modelo
- Visualiza el progreso del entrenamiento

O usa el script de lÃ­nea de comandos:
```bash
python src/train.py --epochs 10 --batch-size 64 --lr 0.001
```

### 4. EvaluaciÃ³n (Notebook 3)

Abre y ejecuta `notebooks/03-evaluacion.ipynb`:
- EvalÃºa el modelo en el conjunto de prueba
- Genera matriz de confusiÃ³n
- Analiza errores comunes
- Visualiza predicciones

O usa el script:
```bash
python src/evaluate.py --model-path checkpoints/best_model.pth
```

## ğŸ—ï¸ Arquitectura del Modelo

Red Neuronal Convolucional (CNN) bÃ¡sica:

```
Input (1x28x28)
    â†“
Conv2d (32 filtros, kernel 3x3)
    â†“
ReLU
    â†“
MaxPool2d (2x2)
    â†“
Conv2d (64 filtros, kernel 3x3)
    â†“
ReLU
    â†“
MaxPool2d (2x2)
    â†“
Flatten
    â†“
Linear (128 unidades)
    â†“
ReLU
    â†“
Dropout (0.5)
    â†“
Linear (10 unidades - salida)
```

## ğŸ“ˆ Resultados Esperados

Con la configuraciÃ³n por defecto, deberÃ­as obtener:
- **Accuracy en entrenamiento**: ~99%
- **Accuracy en prueba**: ~98-99%
- **Tiempo de entrenamiento**: 5-10 minutos (CPU), 1-2 minutos (GPU)

## ğŸ”¬ Experimentos Sugeridos

1. **Arquitectura**:
   - Agrega mÃ¡s capas convolucionales
   - Prueba diferentes tamaÃ±os de kernel
   - Experimenta con diferentes activaciones

2. **HiperparÃ¡metros**:
   - Cambia el learning rate
   - Ajusta el batch size
   - Prueba diferentes optimizadores (SGD, RMSprop)

3. **RegularizaciÃ³n**:
   - Ajusta el dropout
   - Implementa L2 regularization
   - Prueba data augmentation

4. **TÃ©cnicas Avanzadas**:
   - Implementa learning rate scheduling
   - Usa batch normalization
   - Prueba early stopping

## ğŸ“Š Visualizaciones

El laboratorio incluye:
- Curvas de entrenamiento (loss y accuracy)
- Matriz de confusiÃ³n
- Ejemplos de predicciones correctas e incorrectas
- VisualizaciÃ³n de filtros convolucionales

## ğŸ’¾ Modelos Guardados

Los modelos entrenados se guardan en `checkpoints/`:
- `best_model.pth`: Mejor modelo segÃºn validaciÃ³n
- `last_model.pth`: Ãšltimo checkpoint
- `model_epoch_X.pth`: Checkpoints por Ã©poca

## ğŸ› Troubleshooting

**Problema**: Out of memory
- **SoluciÃ³n**: Reduce el batch size

**Problema**: Entrenamiento muy lento
- **SoluciÃ³n**: Verifica que estÃ©s usando GPU si estÃ¡ disponible

**Problema**: Overfitting
- **SoluciÃ³n**: Aumenta dropout o reduce la complejidad del modelo

## ğŸ“š Referencias

- [PyTorch MNIST Tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html)
- [LeCun et al. - MNIST Database](http://yann.lecun.com/exdb/mnist/)
- [CS231n - Convolutional Networks](http://cs231n.github.io/convolutional-networks/)

## ğŸ“ Siguientes Pasos

DespuÃ©s de completar este laboratorio:
1. Intenta con datasets mÃ¡s complejos (CIFAR-10, Fashion-MNIST)
2. Implementa transfer learning con modelos pre-entrenados
3. Despliega tu modelo como una API REST

## ğŸ¤ Contribuir

Â¿Mejoras o extensiones? Â¡Pull requests bienvenidos!

---

**Â¡Feliz experimentaciÃ³n!** ğŸš€
