{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15fd0e3f",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rbernalc/pytorch-mx/blob/main/tutorials/basic/Tutorials_Basic_colab.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc004859",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Tutoriales Basicos  PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302f5b4a",
   "metadata": {},
   "source": [
    "# Tensores\n",
    "\n",
    "Los tensores son una estructura de datos especializada similar a los arreglos y matrices.\n",
    "En PyTorch, usamos tensores para codificar las entradas y salidas de un modelo, así como los parámetros del modelo.\n",
    "\n",
    "Los tensores son similares a los ndarrays de [NumPy](https://numpy.org/), excepto que los tensores pueden ejecutarse en GPUs u otros aceleradores de hardware. De hecho, los tensores y los arreglos de NumPy a menudo pueden compartir la misma memoria subyacente, eliminando la necesidad de copiar datos. Los tensores también están optimizados para diferenciación automática (veremos más sobre eso más adelante en la sección [Autograd](autogradqs_tutorial.html)). Si estás familiarizado con ndarrays, te sentirás como en casa con la API de Tensores. ¡Si no, sigue adelante!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530159a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e67927",
   "metadata": {},
   "source": [
    "## Inicializar un Tensor\n",
    "\n",
    "Los tensores pueden ser inicializados de varias maneras. Echa un vistazo a los siguientes ejemplos:\n",
    "\n",
    "### Directamente desde datos\n",
    "\n",
    "Los tensores pueden ser creados directamente desde datos. El tipo de dato se infiere automáticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74961f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "x_data.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4652b1",
   "metadata": {},
   "source": [
    "### Desde un arreglo NumPy\n",
    "\n",
    "Los tensores pueden ser creados desde arreglos NumPy (y viceversa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310bebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b30d5c",
   "metadata": {},
   "source": [
    "### Desde otro tensor:\n",
    "\n",
    "El nuevo tensor mantiene las propiedades (forma, tipo de dato) del tensor argumento, a menos que se anule explícitamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce6b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ones = torch.ones_like(x_data) # mantiene las propiedades de x_data\n",
    "print(f\"Tensor de Unos: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # anula el tipo de dato de x_data\n",
    "print(f\"Tensor Aleatorio: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a5a443",
   "metadata": {},
   "source": [
    "### Con valores aleatorios o constantes:\n",
    "\n",
    "Para el siguiente ejemplo ``shape`` es una tupla de dimensiones del tensor. En las funciones de abajo, determina la dimensionalidad del tensor de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6712e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (2,3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Tensor Aleatorio: \\n {rand_tensor} \\n\")\n",
    "print(f\"Tensor de Unos: \\n {ones_tensor} \\n\")\n",
    "print(f\"Tensor de Ceros: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0014a25",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Atributos de un Tensor\n",
    "\n",
    "Los atributos del tensor describen su forma, tipo de dato y el dispositivo en el que están almacenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3de0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Forma del tensor: {tensor.shape}\")\n",
    "print(f\"Tipo de dato del tensor: {tensor.dtype}\")\n",
    "print(f\"Dispositivo donde está almacenado el tensor: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6dc03",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Operaciones en Tensores\n",
    "\n",
    "PyTorch contiene más de 1200 operaciones de tensores, incluyendo aritmética, álgebra lineal, manipulación de matrices (transponer,\n",
    "indexar, rebanar), muestreo y más, las cuales están descritas exhaustivamente [aquí](https://pytorch.org/docs/stable/torch.html).\n",
    "\n",
    "Cada una de estas operaciones puede ejecutarse en la CPU y en [Acelerador](https://pytorch.org/docs/stable/torch.html#accelerators)\n",
    "como CUDA, MPS, MTIA, o XPU. Al usar Colab, asigna un acelerador yendo a Runtime > Change runtime type > GPU.\n",
    "\n",
    "Por defecto, los tensores se crean en la CPU. Necesitamos mover explícitamente los tensores al acelerador usando\n",
    "el método ``.to`` (después de verificar la disponibilidad del acelerador). Ten en cuenta que copiar tensores grandes\n",
    "entre dispositivos puede ser costoso en términos de tiempo y memoria!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a18e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movemos nuestro tensor al acelerador actual si está disponible\n",
    "if torch.accelerator.is_available():\n",
    "    tensor = tensor.to(torch.accelerator.current_accelerator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc2ad43",
   "metadata": {},
   "source": [
    "A continuación se muestran algunas de las operaciones de la lista.\n",
    "Si estás familiarizado con la API de NumPy, encontrarás que la API de Tensores es muy fácil de usar.\n",
    "\n",
    "### Indexación y rebanado (slicing) estándar tipo numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9911e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(f\"Primera fila: {tensor[0]}\")\n",
    "print(f\"Primera columna: {tensor[:, 0]}\")\n",
    "print(f\"Última columna: {tensor[..., -1]}\")\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8a5555",
   "metadata": {},
   "source": [
    "### Unir tensores\n",
    "\n",
    "Puedes usar ``torch.cat`` para concatenar una secuencia de tensores a lo largo de una dimensión dada.\n",
    "Existe otro oeprador de union llamadao [torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html), que es sutilmente diferente de ``torch.cat``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3738279",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc806265",
   "metadata": {},
   "source": [
    "### Operaciones aritméticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caca66f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto calcula la multiplicación de matrices entre dos tensores usando matmul o su función equivalente @. \n",
    "# y1, y2, y3 tendrán el mismo valor\n",
    "# ``tensor.T`` devuelve la transpuesta de un tensor\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dac5a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto calcula el producto elemento por elemento. z1, z2, z3 tendrán el mismo valor\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b425774",
   "metadata": {},
   "source": [
    "### Tensores de un solo elemento\n",
    "\n",
    "Si tienes un tensor de un elemento, por ejemplo despues de sumar todos los valores de un mismo tensor, puedes convertirlo a un valor numérico de Python usando ``item()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a0a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022c4207",
   "metadata": {},
   "source": [
    "### Operaciones in-place\n",
    "\n",
    "Las operaciones que almacenan el resultado en el mismo lugar (operando) se llaman in-place. Se denotan con un sufijo ``_``.\n",
    "Por ejemplo: ``x.copy_(y)``, ``x.t_()``, cambiarán el contenido de ``x``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5967a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51bdc06",
   "metadata": {},
   "source": [
    "**Nota:**\n",
    "Las operaciones in-place ahorran algo de memoria, pero pueden ser problemáticas al calcular derivadas debido a una pérdida inmediata\n",
    "del historial. Por lo tanto, se desaconseja su uso.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7474ca81",
   "metadata": {},
   "source": [
    "## Puente con NumPy\n",
    "\n",
    "Los tensores en la CPU y los arreglos NumPy pueden compartir sus ubicaciones de memoria subyacente,  de manera que cambiar los valores de uno cambiará los valores del otro.\n",
    "\n",
    "### Tensor a arreglo NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272d9722",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6479a332",
   "metadata": {},
   "source": [
    "Un cambio en el tensor se refleja en el arreglo NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec849fc",
   "metadata": {},
   "source": [
    "### Arreglo NumPy a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee4344",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9c35ba",
   "metadata": {},
   "source": [
    "Los cambios en el arreglo NumPy se reflejan en el tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6de1aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff2317",
   "metadata": {},
   "source": [
    "# Diferenciación Automática con ``torch.autograd``\n",
    "\n",
    "Al entrenar redes neuronales, el algoritmo más frecuentemente usado es\n",
    "**back propagation**. En este algoritmo, los parámetros (pesos del modelo) se\n",
    "ajustan de acuerdo al **gradiente** de la función de pérdida con respecto al\n",
    "parámetro dado.\n",
    "\n",
    "Para calcular esos gradientes, PyTorch tiene un motor de diferenciación automática\n",
    "integrado llamado ``torch.autograd``. Soporta el cálculo automático del gradiente para cualquier\n",
    "gráfico computacional.\n",
    "\n",
    "Considera la red neuronal más simple de una capa, con entrada ``x``, parámetros ``w`` y ``b``, \n",
    "y alguna función de pérdida. Puede ser definida en PyTorch de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eca83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(5)  # tensor de entrada\n",
    "y = torch.zeros(3)  # salida esperada\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb0b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec430e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e838a",
   "metadata": {},
   "source": [
    "En esta red, ``w`` y ``b`` son **parámetros**, los cuales necesitamos\n",
    "optimizar. Por lo tanto, necesitamos poder calcular los gradientes de la\n",
    "función de pérdida con respecto a esas variables. Para hacer eso, establecemos\n",
    "la propiedad ``requires_grad`` de esos tensores.\n",
    "\n",
    "> Puedes establecer el valor de ``requires_grad`` al crear un tensor, o después usando el método ``x.requires_grad_(True)``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c67ed0",
   "metadata": {},
   "source": [
    "Una función que aplicamos a los tensores para construir el gráfico computacional\n",
    "es de hecho un objeto de la clase ``Function``. Este objeto sabe cómo calcular la función\n",
    "en la dirección *hacia adelante*, y también cómo calcular su derivada durante el paso\n",
    "de *propagación hacia atrás*. Una referencia a la función de propagación hacia atrás se\n",
    "almacena en la propiedad ``grad_fn`` de un tensor. Puedes encontrar más información sobre ``Function`` en la [documentación](https://pytorch.org/docs/stable/autograd.html#function)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dc1382",
   "metadata": {},
   "source": [
    "Para optimizar los pesos de los parámetros en la red neuronal, necesitamos\n",
    "calcular las derivadas de nuestra función de pérdida con respecto a los parámetros,\n",
    "es decir, necesitamos $\\frac{\\partial loss}{\\partial w}$ y $\\frac{\\partial loss}{\\partial b}$\n",
    "bajo algunos valores fijos de ``x`` y ``y``. Para calcular esas derivadas, llamamos\n",
    "``loss.backward()``, y luego recuperamos los valores de ``w.grad`` y ``b.grad``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc421914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto calcula la multiplicación de matrices entre dos tensores usando matmul o su función equivalente @. \n",
    "# y1, y2, y3 tendrán el mismo valor\n",
    "# ``tensor.T`` devuelve la transpuesta de un tensor\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aaaca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto calcula el producto elemento por elemento. z1, z2, z3 tendrán el mismo valor\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ec2279",
   "metadata": {},
   "source": [
    "### Tensores de un solo elemento\n",
    "\n",
    "Si tienes un tensor de un elemento, por ejemplo despues de sumar todos los valores de un mismo tensor, puedes convertirlo a un valor numérico de Python usando ``item()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9e2229",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86ba1d2",
   "metadata": {},
   "source": [
    "### Operaciones in-place\n",
    "\n",
    "Las operaciones que almacenan el resultado en el mismo lugar (operando) se llaman in-place. Se denotan con un sufijo ``_``.\n",
    "Por ejemplo: ``x.copy_(y)``, ``x.t_()``, cambiarán el contenido de ``x``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f439229",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c6e2d0",
   "metadata": {},
   "source": [
    "**Nota:**\n",
    "Las operaciones in-place ahorran algo de memoria, pero pueden ser problemáticas al calcular derivadas debido a una pérdida inmediata\n",
    "del historial. Por lo tanto, se desaconseja su uso.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b5dad",
   "metadata": {},
   "source": [
    "## Puente con NumPy\n",
    "\n",
    "Los tensores en la CPU y los arreglos NumPy pueden compartir sus ubicaciones de memoria subyacente,  de manera que cambiar los valores de uno cambiará los valores del otro.\n",
    "\n",
    "### Tensor a arreglo NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4653e2",
   "metadata": {},
   "source": [
    "Un cambio en el tensor se refleja en el arreglo NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c271ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf596c2b",
   "metadata": {},
   "source": [
    "### Arreglo NumPy a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069619a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2c3295",
   "metadata": {},
   "source": [
    "Los cambios en el arreglo NumPy se reflejan en el tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cd58cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7dd944",
   "metadata": {},
   "source": [
    "# Diferenciación Automática con ``torch.autograd``\n",
    "\n",
    "Al entrenar redes neuronales, el algoritmo más frecuentemente usado es\n",
    "**back propagation**. En este algoritmo, los parámetros (pesos del modelo) se\n",
    "ajustan de acuerdo al **gradiente** de la función de pérdida con respecto al\n",
    "parámetro dado.\n",
    "\n",
    "Para calcular esos gradientes, PyTorch tiene un motor de diferenciación automática\n",
    "integrado llamado ``torch.autograd``. Soporta el cálculo automático del gradiente para cualquier\n",
    "gráfico computacional.\n",
    "\n",
    "Considera la red neuronal más simple de una capa, con entrada ``x``, parámetros ``w`` y ``b``, \n",
    "y alguna función de pérdida. Puede ser definida en PyTorch de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33991a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(5)  # tensor de entrada\n",
    "y = torch.zeros(3)  # salida esperada\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6a931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78015d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf27500",
   "metadata": {},
   "source": [
    "En esta red, ``w`` y ``b`` son **parámetros**, los cuales necesitamos\n",
    "optimizar. Por lo tanto, necesitamos poder calcular los gradientes de la\n",
    "función de pérdida con respecto a esas variables. Para hacer eso, establecemos\n",
    "la propiedad ``requires_grad`` de esos tensores.\n",
    "\n",
    "> Puedes establecer el valor de ``requires_grad`` al crear un tensor, o después usando el método ``x.requires_grad_(True)``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564cc84e",
   "metadata": {},
   "source": [
    "Una función que aplicamos a los tensores para construir el gráfico computacional\n",
    "es de hecho un objeto de la clase ``Function``. Este objeto sabe cómo calcular la función\n",
    "en la dirección *hacia adelante*, y también cómo calcular su derivada durante el paso\n",
    "de *propagación hacia atrás*. Una referencia a la función de propagación hacia atrás se\n",
    "almacena en la propiedad ``grad_fn`` de un tensor. Puedes encontrar más información sobre ``Function`` en la [documentación](https://pytorch.org/docs/stable/autograd.html#function)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c481ce",
   "metadata": {},
   "source": [
    "Para optimizar los pesos de los parámetros en la red neuronal, necesitamos\n",
    "calcular las derivadas de nuestra función de pérdida con respecto a los parámetros,\n",
    "es decir, necesitamos $\\frac{\\partial loss}{\\partial w}$ y $\\frac{\\partial loss}{\\partial b}$\n",
    "bajo algunos valores fijos de ``x`` y ``y``. Para calcular esas derivadas, llamamos\n",
    "``loss.backward()``, y luego recuperamos los valores de ``w.grad`` y ``b.grad``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9708ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Gradient function for z = {z.grad_fn}\")\n",
    "print(f\"Gradient function for loss = {loss.grad_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18fbfe8",
   "metadata": {},
   "source": [
    "> **Nota**\n",
    "> - Solo podemos obtener las propiedades ``grad`` para los nodos hoja del gráfico computacional, que tienen la propiedad ``requires_grad`` establecida en ``True``. Para todos los otros nodos en nuestro gráfico, los gradientes no estarán disponibles.\n",
    "> - Solo podemos realizar cálculos de gradiente usando ``backward`` una vez en un gráfico dado por razones de rendimiento. Si necesitamos hacer varias llamadas ``backward`` en el mismo gráfico, necesitamos pasar ``retain_graph=True`` a la llamada ``backward``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e3a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ab558a",
   "metadata": {},
   "source": [
    "## Deshabilitando el Seguimiento del Gradiente\n",
    "\n",
    "Por defecto, todos los tensores con ``requires_grad=True`` están siguiendo su\n",
    "historial computacional y soportan el cálculo del gradiente. Sin embargo, hay algunos casos donde no necesitamos\n",
    "hacer eso, por ejemplo, cuando hemos entrenado el modelo y solo queremos aplicarlo a\n",
    "algunos datos de entrada, es decir, solo queremos hacer cálculos *hacia adelante* a través de la red.\n",
    "Podemos detener el rastreo de los cálculos envolviendo nuestro código de cálculo con el bloque ``torch.no_grad()``:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3be341",
   "metadata": {},
   "source": [
    "Otra forma de lograr el mismo resultado es usando el método ``detach()`` en el tensor:\n",
    "\n",
    "El tensor resultante no tiene ``requires_grad=True``\n",
    "\n",
    "Hay razones por las que podrías querer deshabilitar el seguimiento del gradiente:\n",
    "  - Para marcar algunos parámetros en tu red neuronal como **parámetros congelados**.\n",
    "  - Para **acelerar los cálculos** cuando solo estás haciendo un paso hacia adelante, porque los cálculos en tensores que no rastrean gradientes serían más eficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a61dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee077b16",
   "metadata": {},
   "source": [
    "Otra forma de lograr el mismo resultado es usando el método ``detach()`` en el tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc9d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d5be6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Más sobre el Gráfico Computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dae80bc",
   "metadata": {},
   "source": [
    "Conceptualmente, autograd mantiene un registro de datos (tensores) y todas las operaciones ejecutadas\n",
    "(junto con los nuevos tensores resultantes) en un gráfico acíclico dirigido (DAG) que consiste de\n",
    "objetos [Function](https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function). En este DAG, las hojas\n",
    "son los tensores de entrada, las raíces son los tensores de salida. Rastreando este gráfico desde las raíces hasta las hojas, \n",
    "puedes calcular automáticamente los gradientes usando la regla de la cadena.\n",
    "\n",
    "En un paso hacia adelante, autograd hace dos cosas simultáneamente:\n",
    "\n",
    "- ejecuta la operación solicitada para calcular un tensor resultante\n",
    "- mantiene la *función de gradiente* de la operación en el DAG.\n",
    "\n",
    "El paso hacia atrás se inicia cuando se llama ``.backward()`` en la raíz del DAG.\n",
    "``autograd`` luego:\n",
    "\n",
    "- calcula los gradientes de cada ``.grad_fn``,\n",
    "- los acumula en el atributo ``.grad`` del tensor respectivo\n",
    "- usando la regla de la cadena, se propaga hasta los tensores hoja.\n",
    "\n",
    "> **Nota**\n",
    ">\n",
    "> **DAGs son dinámicos en PyTorch**\n",
    "> Una cosa importante a notar es que el gráfico se recrea desde cero; después de cada llamada a ``.backward()``, autograd comienza a poblar un nuevo gráfico. Esto es exactamente lo que te permite usar declaraciones de flujo de control en tu modelo; puedes cambiar la forma, tamaño y operaciones en cada iteración si es necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69e0550",
   "metadata": {},
   "source": [
    "## Gradientes de Tensores y Funciones Jacobianas\n",
    "\n",
    "En muchos casos, tenemos una función escalar de pérdida, y necesitamos calcular el gradiente \n",
    "con respecto a algunos parámetros. Sin embargo, hay casos donde la función de salida\n",
    "es un tensor arbitrario. En este caso, PyTorch te permite calcular el llamado **producto Jacobiano-vector**, en lugar de la matriz Jacobiana actual.\n",
    "\n",
    "Para un vector función $\\vec{y}=f(\\vec{x})$, donde $\\vec{x}=\\langle x_1,\\ldots,x_n\\rangle$ y\n",
    "$\\vec{y}=\\langle y_1,\\ldots,y_m\\rangle$, un gradiente de $\\vec{y}$ con respecto a\n",
    "$\\vec{x}$ es dado por la **matriz Jacobiana**:\n",
    "\n",
    "$$J=\\left(\\begin{array}{ccc}\n",
    "   \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n",
    "   \\vdots & \\ddots & \\vdots\\\\\n",
    "   \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
    "   \\end{array}\\right)$$\n",
    "\n",
    "En lugar de calcular la matriz Jacobiana en sí misma, PyTorch te permite calcular el **producto Jacobiano-vector** $J^T \\cdot v$ para un vector dado $v$. Esto se logra\n",
    "llamando a ``backward`` con $v$ como argumento. El tamaño de $v$ debería ser el mismo que\n",
    "el tamaño del tensor original, con respecto al cual queremos calcular el producto:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388fad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.eye(4, 5, requires_grad=True)\n",
    "out = (inp+1).pow(2).t()\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"Primer llamado\\n{inp.grad}\")\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"\\nSegundo llamado\\n{inp.grad}\")\n",
    "inp.grad.zero_()\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"\\nLlamado después de poner los gradientes en cero\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cb1d87",
   "metadata": {},
   "source": [
    "Observa que cuando llamamos ``backward`` por segunda vez con los mismos argumentos, el valor de\n",
    "los gradientes es diferente. Esto sucede porque al hacer la propagación hacia atrás, PyTorch\n",
    "**acumula los gradientes**, es decir, el valor de los gradientes calculados se suma al atributo ``.grad`` \n",
    "de todos los nodos hoja del gráfico computacional. Si quieres calcular los gradientes apropiados, necesitas\n",
    "poner la propiedad ``.grad`` en cero antes. En el entrenamiento de la vida real esto es hecho para nosotros por el optimizador.\n",
    "\n",
    "> **Nota**\n",
    ">\n",
    "> Anteriormente estábamos llamando a la función ``backward()`` sin parámetros. Esto es esencialmente equivalente a \n",
    "> llamar ``backward(torch.tensor(1.0))``, lo cual es una forma útil de calcular los gradientes en el caso de \n",
    "> una función escalar, como la pérdida durante el entrenamiento de redes neuronales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99423cd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lectura Adicional\n",
    "\n",
    "- [API de Autograd](https://pytorch.org/docs/stable/autograd.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1bf5a4",
   "metadata": {},
   "source": [
    "# Conjuntos de Datos y DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0e7f71",
   "metadata": {},
   "source": [
    "El código para procesar muestras de datos puede volverse desordenado y difícil de mantener; idealmente queremos que nuestro código de conjunto de datos\n",
    "esté desacoplado de nuestro código de entrenamiento del modelo para mejor legibilidad y modularidad.\n",
    "PyTorch proporciona dos primitivas de datos: ``torch.utils.data.DataLoader`` y ``torch.utils.data.Dataset``\n",
    "que te permiten usar conjuntos de datos pre-cargados así como tus propios datos.\n",
    "``Dataset`` almacena las muestras y sus etiquetas correspondientes, y ``DataLoader`` envuelve un iterable alrededor\n",
    "del ``Dataset`` para habilitar acceso fácil a las muestras.\n",
    "\n",
    "Las bibliotecas de dominio de PyTorch proporcionan un número de conjuntos de datos pre-cargados (como FashionMNIST) que\n",
    "son subclases de ``torch.utils.data.Dataset`` e implementan funciones específicas para los datos particulares.\n",
    "Pueden usarse para prototipar y hacer benchmark de tu modelo. Puedes encontrarlos\n",
    "aquí: [Conjuntos de Datos de Imágenes](https://pytorch.org/vision/stable/datasets.html),\n",
    "[Conjuntos de Datos de Texto](https://pytorch.org/text/stable/datasets.html), y\n",
    "[Conjuntos de Datos de Audio](https://pytorch.org/audio/stable/datasets.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2313a74c",
   "metadata": {},
   "source": [
    "## Cargar un Conjunto de Datos\n",
    "\n",
    "Aquí hay un ejemplo de cómo cargar el conjunto de datos [Fashion-MNIST](https://research.zalando.com/project/fashion_mnist/fashion_mnist/) de TorchVision.\n",
    "Fashion-MNIST es un conjunto de datos de imágenes de artículos de Zalando que consiste en 60,000 ejemplos de entrenamiento y 10,000 ejemplos de prueba.\n",
    "Cada ejemplo comprende una imagen en escala de grises de 28×28 y una etiqueta asociada de una de 10 clases.\n",
    "\n",
    "Cargamos el [Conjunto de Datos FashionMNIST](https://pytorch.org/vision/stable/datasets.html#fashion-mnist) con los siguientes parámetros:\n",
    "- ``root`` es la ruta donde se almacenan los datos de entrenamiento/prueba,\n",
    "- ``train`` especifica conjunto de datos de entrenamiento o prueba,\n",
    "- ``download=True`` descarga los datos de internet si no están disponibles en ``root``.\n",
    "- ``transform`` y ``target_transform`` especifican las transformaciones de características y etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a5f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7eb163",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c4ed6",
   "metadata": {},
   "source": [
    "## Iterar y Visualizar el Conjunto de Datos\n",
    "\n",
    "Podemos indexar ``Datasets`` manualmente como una lista: ``training_data[index]``.\n",
    "Usamos ``matplotlib`` para visualizar algunas muestras en nuestros datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04a32a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"Camiseta\",\n",
    "    1: \"Pantalón\", \n",
    "    2: \"Suéter\",\n",
    "    3: \"Vestido\",\n",
    "    4: \"Abrigo\",\n",
    "    5: \"Sandalia\",\n",
    "    6: \"Camisa\",\n",
    "    7: \"Zapatilla\",\n",
    "    8: \"Bolso\",\n",
    "    9: \"Botín\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802055d0",
   "metadata": {},
   "source": [
    "## Crear un Conjunto de Datos Personalizado para tus archivos\n",
    "\n",
    "Una clase Dataset personalizada debe implementar tres funciones: `__init__`, `__len__`, y `__getitem__`.\n",
    "Echa un vistazo a esta implementación; las imágenes de FashionMNIST están almacenadas\n",
    "en un directorio ``img_dir``, y sus etiquetas están almacenadas separadamente en un archivo CSV ``annotations_file``.\n",
    "\n",
    "En las siguientes secciones, desglosaremos qué está sucediendo en cada una de estas funciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb4cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import decode_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = decode_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840b34fb",
   "metadata": {},
   "source": [
    "### `__init__`\n",
    "\n",
    "La función __init__ se ejecuta una vez al instanciar el objeto Dataset. Inicializamos\n",
    "el directorio que contiene las imágenes, el archivo de anotaciones, y ambas transformaciones (cubiertas\n",
    "en más detalle en la siguiente sección).\n",
    "\n",
    "El archivo labels.csv se ve así:\n",
    "\n",
    "```\n",
    "tshirt1.jpg, 0\n",
    "tshirt2.jpg, 0\n",
    "......\n",
    "ankleboot999.jpg, 9\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "    self.img_labels = pd.read_csv(annotations_file)\n",
    "    self.img_dir = img_dir\n",
    "    self.transform = transform\n",
    "    self.target_transform = target_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6881efe6",
   "metadata": {},
   "source": [
    "### `__len__`\n",
    "\n",
    "La función __len__ devuelve el número de muestras en nuestro conjunto de datos.\n",
    "\n",
    "Ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d176f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __len__(self):\n",
    "    return len(self.img_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c96ab1",
   "metadata": {},
   "source": [
    "### `__getitem__`\n",
    "\n",
    "La función __getitem__ carga y devuelve una muestra del conjunto de datos en el índice dado ``idx``.\n",
    "Basado en el índice, identifica la ubicación de la imagen en el disco, la convierte a un tensor usando ``read_image``, \n",
    "recupera la etiqueta correspondiente desde el archivo csv en ``self.img_labels``, llama a las funciones de transformación \n",
    "en ellos (si aplica), y devuelve la muestra del tensor y la etiqueta correspondiente en una tupla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc21a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getitem__(self, idx):\n",
    "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "    image = decode_image(img_path)\n",
    "    label = self.img_labels.iloc[idx, 1]\n",
    "    if self.transform:\n",
    "        image = self.transform(image)\n",
    "    if self.target_transform:\n",
    "        label = self.target_transform(label)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b37d06",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Preparar tus datos para el entrenamiento con DataLoaders\n",
    "\n",
    "El ``Dataset`` recupera las características de nuestro conjunto de datos y etiqueta una muestra a la vez. Mientras entrenamos un modelo, típicamente queremos pasar muestras en \"minibatches\", reordenar los datos en cada época para reducir el overfitting del modelo, y usar el multiprocesamiento de Python para acelerar la recuperación de datos.\n",
    "\n",
    "``DataLoader`` es un iterable que abstrae esta complejidad para nosotros en una API fácil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4decfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c350a1b6",
   "metadata": {},
   "source": [
    "## Iterar a través del DataLoader\n",
    "\n",
    "Hemos cargado ese conjunto de datos en el ``DataLoader`` y podemos iterar a través del conjunto de datos según sea necesario.\n",
    "Cada iteración a continuación devuelve un lote de ``train_features`` y ``train_labels`` (conteniendo elementos de ``batch_size=64`` cada uno).\n",
    "Debido a que especificamos ``shuffle=True``, después de que iteremos sobre todos los lotes, los datos se mezclan (para un control más detallado sobre el orden de carga de los datos, echa un vistazo a [Samplers](https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3278a480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar imagen y etiqueta.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Forma del lote de características: {train_features.size()}\")\n",
    "print(f\"Forma del lote de etiquetas: {train_labels.size()}\")\n",
    "print(train_features[0].shape)\n",
    "img = train_features[0].squeeze()\n",
    "print(img.shape)\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Etiqueta: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7f848b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lectura Adicional\n",
    "- [torch.utils.data API](https://pytorch.org/docs/stable/data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73004974",
   "metadata": {},
   "source": [
    "# Transformaciones\n",
    "\n",
    "Los datos no siempre vienen en su forma final procesada que es requerida para\n",
    "entrenar algoritmos de aprendizaje automático. Usamos **transformaciones** para realizar\n",
    "alguna manipulación de los datos y hacerlos adecuados para el entrenamiento.\n",
    "\n",
    "Todas las datasets de TorchVision tienen dos parámetros - ``transform`` para modificar\n",
    "las características e ``target_transform`` para modificar las etiquetas - que\n",
    "aceptan callables conteniendo la lógica de transformación.\n",
    "El módulo [torchvision.transforms](https://pytorch.org/vision/stable/transforms.html) ofrece\n",
    "varias transformaciones predefinidas comúnmente usadas listas para usar.\n",
    "\n",
    "Las características de FashionMNIST están en formato de imagen PIL, y las etiquetas son enteros.\n",
    "Para el entrenamiento, necesitamos las características como tensores normalizados, y las etiquetas\n",
    "como tensores de one-hot encoded. Para hacer estas transformaciones, usamos ``ToTensor`` e ``Lambda``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6b6239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95481a44",
   "metadata": {},
   "source": [
    "## ToTensor()\n",
    "\n",
    "[ToTensor](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ToTensor)\n",
    "convierte una imagen PIL o arreglo NumPy a un ``FloatTensor``. y escala\n",
    "los valores de intensidad de pixel de la imagen en el rango [0., 1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb18568",
   "metadata": {},
   "source": [
    "## Lambda Transforms\n",
    "\n",
    "Las transformaciones Lambda aplican cualquier función lambda definida por el usuario. Aquí, definimos una función\n",
    "para convertir el entero a un tensor one-hot encoded.\n",
    "Primero crea un tensor zero del tamaño 10 (el número de etiquetas en nuestro conjunto de datos)\n",
    "y llama a [scatter](https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html) el cual asigna un\n",
    "``value=1`` en el índice dado por la etiqueta ``y``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa16baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_transform = Lambda(lambda y: torch.zeros(\n",
    "    10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accb85c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.zeros(10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(8), value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d2522b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lectura Adicional\n",
    "\n",
    "- [Transformaciones de TorchVision](https://pytorch.org/vision/stable/transforms.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5a75d2",
   "metadata": {},
   "source": [
    "# Construir la Red Neuronal\n",
    "\n",
    "Las redes neuronales se componen de capas/módulos que realizan operaciones en datos.\n",
    "El espacio de nombres [torch.nn](https://pytorch.org/docs/stable/nn.html) proporciona todos los bloques de construcción que necesitas para\n",
    "construir tu propia red neuronal. Cada módulo en PyTorch es una subclase de [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n",
    "Una red neuronal es un módulo en sí mismo que consiste en otros módulos (capas). Esta estructura anidada permite\n",
    "construir y gestionar arquitecturas complejas fácilmente.\n",
    "\n",
    "En las siguientes secciones, construiremos una red neuronal para clasificar imágenes en el conjunto de datos FashionMNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6d1379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8330f652",
   "metadata": {},
   "source": [
    "## Obtener Dispositivo para Entrenamiento\n",
    "\n",
    "Queremos poder entrenar nuestro modelo en un [acelerador](https://pytorch.org/docs/stable/torch.html#accelerators)\n",
    "como CUDA, MPS, MTIA, o XPU. Si el acelerador actual está disponible, lo usaremos. De lo contrario, usamos la CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c19d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Usando dispositivo {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5abc3b1",
   "metadata": {},
   "source": [
    "## Definir la Clase\n",
    "\n",
    "Definimos nuestra red neuronal heredando de ``nn.Module``, e\n",
    "inicializamos las capas de la red neuronal en ``__init__``. Cada subclase de ``nn.Module`` implementa\n",
    "las operaciones en datos de entrada en el método ``forward``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410c6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b00198",
   "metadata": {},
   "source": [
    "Creamos una instancia de ``NeuralNetwork``, la movemos al ``device``, e imprimimos\n",
    "su estructura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12e99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec798055",
   "metadata": {},
   "source": [
    "Para usar el modelo, le pasamos los datos de entrada. Esto ejecuta el ``forward`` del modelo,\n",
    "junto con algunas [operaciones en segundo plano](https://github.com/pytorch/pytorch/blob/270111b7b611d174967ed204776985cefca9c144/torch/nn/modules/module.py#L866).\n",
    "¡No llames a ``model.forward()`` directamente!\n",
    "\n",
    "Llamar al modelo con la entrada devuelve un tensor bidimensional con dim=0 correspondiente a cada salida de 10 valores predichos sin procesar para cada clase, y dim=1 correspondiente a los valores individuales de cada salida.\n",
    "Obtenemos las probabilidades de predicción pasándolo a través de una instancia del módulo ``nn.Softmax``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79f16d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f08771d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Capas del Modelo\n",
    "\n",
    "Desglosemos las capas en el modelo FashionMNIST. Para ilustrarlo,\n",
    "tomaremos un minilote de muestra de 3 imágenes de tamaño 28x28 y veremos qué le sucede mientras\n",
    "lo pasamos a través de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b866ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c011a922",
   "metadata": {},
   "source": [
    "### nn.Flatten\n",
    "\n",
    "Inicializamos la capa [nn.Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)\n",
    "para convertir cada imagen 2D de 28x28 en un arreglo contiguo de 784 valores de píxeles (\n",
    "la dimensión del minilote (en dim=0) se mantiene)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af812831",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a4123",
   "metadata": {},
   "source": [
    "### nn.Linear\n",
    "\n",
    "La [capa lineal](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
    "es un módulo que aplica una transformación lineal en la entrada usando sus pesos y sesgos almacenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a79c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aebd5d",
   "metadata": {},
   "source": [
    "### nn.ReLU\n",
    "\n",
    "Las activaciones no lineales son las que crean las asignaciones complejas entre las entradas y salidas del modelo.\n",
    "Se aplican después de las transformaciones lineales para introducir *no linealidad*, ayudando a las redes neuronales\n",
    "a aprender una amplia variedad de fenómenos.\n",
    "\n",
    "En este modelo, usamos [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) entre nuestras\n",
    "capas lineales, pero hay otras activaciones para introducir no linealidad en tu modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c14d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fd0ffa",
   "metadata": {},
   "source": [
    "### nn.Sequential\n",
    "\n",
    "[nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) es un contenedor ordenado\n",
    "de módulos. Los datos se pasan a través de todos los módulos en el mismo orden en que se definen. Puedes usar\n",
    "contenedores secuenciales para armar rápidamente una red como ``seq_modules``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddbc1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b30463",
   "metadata": {},
   "source": [
    "### nn.Softmax\n",
    "\n",
    "La última capa lineal de la red neuronal devuelve `logits` - valores sin procesar en [-∞, ∞] - que se pasan al\n",
    "módulo [nn.Softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html). Los logits se escalan a valores\n",
    "[0, 1] que representan las probabilidades predichas del modelo para cada clase. El parámetro ``dim`` indica la dimensión a lo largo de\n",
    "la cual los valores deben sumar 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d874c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "pred_probab*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc0f237",
   "metadata": {},
   "source": [
    "## Parámetros del Modelo\n",
    "\n",
    "Muchas capas dentro de una red neuronal están *parametrizadas*, es decir, tienen pesos\n",
    "y sesgos asociados que se optimizan durante el entrenamiento. Heredar de ``nn.Module`` automáticamente\n",
    "rastrea todos los campos definidos dentro de tu objeto modelo, y hace que todos los parámetros\n",
    "sean accesibles usando los métodos ``parameters()`` o ``named_parameters()`` de tu modelo.\n",
    "\n",
    "En este ejemplo, iteramos sobre cada parámetro, e imprimimos su tamaño y una vista previa de sus valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9165cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6620a3e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lectura Adicional\n",
    "\n",
    "- [torch.nn API](https://pytorch.org/docs/stable/nn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d625cb",
   "metadata": {},
   "source": [
    "# Optimizando los Parámetros del Modelo\n",
    "\n",
    "Ahora que tenemos un modelo y datos, es tiempo de entrenar, validar y probar nuestro modelo optimizando sus parámetros en nuestros datos. Entrenar un modelo es un proceso iterativo; en cada iteración el modelo hace una suposición sobre la salida, calcula el error en su suposición (*pérdida*), recolecta las derivadas del error con respecto a sus parámetros (como vimos en la sección anterior), y **optimiza** estos parámetros usando descenso de gradiente. Para un recorrido más detallado de este proceso, revisa este video en [backpropagation from 3Blue1Brown](https://www.youtube.com/watch?v=tIeHLnjs5U8).\n",
    "\n",
    "## Código Prerrequisito\n",
    "Cargamos el código de las secciones anteriores en `Datasets & DataLoaders` y `Build Model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80244d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb49d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener datos de entrenamiento y prueba\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097cf9de",
   "metadata": {},
   "source": [
    "## Hiperparámetros\n",
    "\n",
    "Los hiperparámetros son parámetros ajustables que te permiten controlar el proceso de optimización del modelo. Diferentes valores de hiperparámetros pueden impactar el entrenamiento del modelo y las tasas de convergencia ([leer más sobre ajuste de hiperparámetros](https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html))\n",
    "\n",
    "Definimos los siguientes hiperparámetros para el entrenamiento:\n",
    " - **Número de Épocas** - el número de veces para iterar sobre el conjunto de datos\n",
    " - **Tamaño de Lote** - el número de muestras de datos propagadas a través de la red antes de que los parámetros se actualicen\n",
    " - **Tasa de Aprendizaje** - cuánto actualizar los parámetros del modelo en cada lote/época. Valores más pequeños resultan en una velocidad de aprendizaje lenta, mientras que valores grandes pueden resultar en un comportamiento impredecible durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27e9643",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1362cb58",
   "metadata": {},
   "source": [
    "## Bucle de Optimización\n",
    "\n",
    "Una vez que establecemos nuestros hiperparámetros, podemos entrenar y optimizar nuestro modelo con un bucle de optimización. Cada iteración del bucle de optimización se llama una **época**. \n",
    "\n",
    "Cada época consiste de dos partes principales:\n",
    " - **El Bucle de Entrenamiento** - itera sobre el conjunto de datos de entrenamiento e intenta converger a parámetros óptimos.\n",
    " - **El Bucle de Validación/Prueba** - itera sobre el conjunto de datos de prueba para verificar si el rendimiento del modelo está mejorando.\n",
    "\n",
    "Vamos a familiarizarnos brevemente con algunos de los conceptos usados en el bucle de entrenamiento. Adelante, salta para ver la [Implementación Completa](#implementación-completa) del bucle de optimización.\n",
    "\n",
    "### Función de Pérdida\n",
    "\n",
    "Cuando se presenta con algunos datos de entrenamiento, nuestro modelo no entrenado probablemente no dará la respuesta correcta. **Función de pérdida** mide el grado de disimilitud del resultado obtenido al valor objetivo, y es la función de pérdida lo que queremos minimizar durante el entrenamiento. Para calcular la pérdida sumamos las predicciones de nuestro modelo en los puntos de datos dados y las comparamos contra los valores objetivo reales.\n",
    "\n",
    "Las funciones de pérdida comunes incluyen [nn.MSELoss](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss) (Error Cuadrático Medio) para tareas de regresión, y [nn.NLLLoss](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss) (Pérdida Logarítmica Negativa) para clasificación. [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) combina ``nn.LogSoftmax`` y ``nn.NLLLoss``.\n",
    "\n",
    "Pasamos las predicciones de salida de nuestro modelo a ``nn.CrossEntropyLoss``, que normalizará las predicciones y calculará la pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c9de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar la función de pérdida\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d16697b",
   "metadata": {},
   "source": [
    "### Optimizador\n",
    "\n",
    "La optimización es el proceso de ajustar los parámetros del modelo para reducir el error del modelo en cada paso de entrenamiento. **Algoritmos de optimización** definen cómo se realiza este proceso (en este ejemplo usamos Descenso de Gradiente Estocástico). Toda la lógica de optimización está encapsulada en el objeto ``optimizer``. Aquí, usamos el optimizador SGD; además, hay muchos [diferentes optimizadores](https://pytorch.org/docs/stable/optim.html) disponibles en PyTorch tales como ADAM y RMSProp, que funcionan mejor para diferentes tipos de modelos y datos.\n",
    "\n",
    "Inicializamos el optimizador registrando los parámetros del modelo que necesitan ser entrenados, y pasando el hiperparámetro de la tasa de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c014e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ceae87",
   "metadata": {},
   "source": [
    "Dentro del bucle de entrenamiento, la optimización sucede en tres pasos:\n",
    " * Llama a ``optimizer.zero_grad()`` para reiniciar los gradientes de los parámetros del modelo. Los gradientes por defecto se suman; para prevenir el doble conteo, los ponemos explícitamente en cero en cada iteración.\n",
    " * Retropropaga la pérdida de predicción con una llamada a ``loss.backward()``. PyTorch deposita los gradientes de la pérdida con respecto a cada parámetro.\n",
    " * Una vez que tenemos nuestros gradientes, llamamos a ``optimizer.step()`` para ajustar los parámetros por los gradientes recolectados en el paso hacia atrás."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae76194",
   "metadata": {},
   "source": [
    "## Implementación Completa\n",
    "Definimos las funciones ``train_loop`` que recorre el bucle de optimización, y ``test_loop`` que evalúa el rendimiento del modelo contra nuestros datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23027c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Calcular predicción y pérdida\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Retropropagación\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"pérdida: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5602577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Rendimiento de Prueba: \\n Precisión: {(100*correct):>0.1f}%, Pérdida Promedio: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a8700f",
   "metadata": {},
   "source": [
    "Inicializamos la función de pérdida y optimizador, y los pasamos a ``train_loop`` y ``test_loop``.\n",
    "Siéntete libre de incrementar el número de épocas para rastrear el rendimiento de mejora del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db83d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Época {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"¡Terminado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea94ebe4",
   "metadata": {},
   "source": [
    "## Inferencia del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a1122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"Camiseta/top\",\n",
    "    \"Pantalón\",\n",
    "    \"Suéter\",\n",
    "    \"Vestido\",\n",
    "    \"Abrigo\",\n",
    "    \"Sandalia\",\n",
    "    \"Camisa\",\n",
    "    \"Zapatilla\",\n",
    "    \"Bolsa\",\n",
    "    \"Bota\",\n",
    "]\n",
    "\n",
    "# Mostrar las primeras 4 imágenes de los conjuntos de datos de entrenamiento y prueba\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Crear subgráficas para los datos de entrenamiento\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "fig.suptitle('Conjunto de Datos Fashion-MNIST - Primeras 4 Imágenes', fontsize=16)\n",
    "\n",
    "# Mostrar las primeras 4 imágenes de entrenamiento\n",
    "for i in range(4):\n",
    "    image, label = training_data[i]\n",
    "    axes[0, i].imshow(image.squeeze(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Entrena: {classes[label]}')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "# Mostrar las primeras 4 imágenes de prueba\n",
    "for i in range(4):\n",
    "    image, label = test_data[i]\n",
    "    axes[1, i].imshow(image.squeeze(), cmap='gray')\n",
    "    axes[1, i].set_title(f'Prueba: {classes[label]}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Imprimir detalles de las imágenes\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {len(training_data)}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {len(test_data)}\")\n",
    "print(f\"Forma de la imagen: {training_data[0][0].shape}\")\n",
    "print(f\"Número de clases: {len(classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f034a1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lectura Adicional\n",
    "- [Función de Pérdida](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "- [torch.optim](https://pytorch.org/docs/stable/optim.html)\n",
    "- [Tutorial de Warmstart Training](https://pytorch.org/tutorials/recipes/recipes/warmstarting_model_using_parameters_from_a_different_model.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19de73c6",
   "metadata": {},
   "source": [
    "## 7. Guardar Modelo\n",
    "\n",
    "PyTorch proporciona diferentes formas de guardar modelos. Puedes guardar solo los pesos del modelo o también el estado completo incluyendo el optimizador, la época actual, y otras métricas importantes para poder reanudar el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a612da",
   "metadata": {},
   "source": [
    "### 7.1 Guardar solo los pesos del modelo\n",
    "\n",
    "La forma más simple es guardar únicamente los parámetros (pesos) del modelo usando `state_dict()`. Esto es útil cuando solo necesitas el modelo entrenado para hacer inferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5cf431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Crear directorio para guardar modelos si no existe\n",
    "os.makedirs('modelos_guardados', exist_ok=True)\n",
    "\n",
    "# Guardar solo los pesos del modelo\n",
    "torch.save(model.state_dict(), 'modelos_guardados/modelo_pesos.pth')\n",
    "print(\"✓ Modelo guardado en 'modelos_guardados/modelo_pesos.pth'\")\n",
    "\n",
    "# Para cargar el modelo más tarde:\n",
    "# model = NeuralNetwork()  # Primero crear la arquitectura\n",
    "# model.load_state_dict(torch.load('modelos_guardados/modelo_pesos.pth'))\n",
    "# model.eval()  # Poner en modo evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250bf17a",
   "metadata": {},
   "source": [
    "### 7.2 Guardar checkpoint completo\n",
    "\n",
    "Un checkpoint completo incluye no solo los pesos del modelo, sino también el estado del optimizador, la época actual, el loss, y cualquier otra información necesaria para reanudar el entrenamiento exactamente donde lo dejaste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bad3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar un checkpoint completo\n",
    "epoch = 5\n",
    "loss_value = 0.25\n",
    "\n",
    "checkpoint = {\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss_value,\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint_epoch_5.pth')\n",
    "print(f\"✓ Checkpoint guardado en época {epoch}\")\n",
    "\n",
    "# Para cargar el checkpoint y reanudar el entrenamiento:\n",
    "# checkpoint = torch.load('modelos_guardados/checkpoint_epoch_5.pth')\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ba239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f6ea382",
   "metadata": {},
   "source": [
    "### 7.3 Guardar checkpoints durante el entrenamiento\n",
    "\n",
    "Ejemplo práctico: guardar un checkpoint cada N épocas durante el entrenamiento. Esto es muy útil para entrenamientos largos donde puedes querer guardar el progreso periódicamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a54ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_checkpoints(model, train_dataloader, optimizer, loss_fn, epochs, device, save_every=5):\n",
    "    \"\"\"\n",
    "    Función de entrenamiento que guarda checkpoints cada N épocas\n",
    "    \n",
    "    Args:\n",
    "        model: El modelo a entrenar\n",
    "        train_dataloader: DataLoader con datos de entrenamiento\n",
    "        optimizer: Optimizador\n",
    "        loss_fn: Función de pérdida\n",
    "        epochs: Número total de épocas\n",
    "        device: Dispositivo (CPU o GPU)\n",
    "        save_every: Guardar checkpoint cada N épocas\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch, (X, y) in enumerate(train_dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "        print(f\"Época {epoch+1}/{epochs} - Loss promedio: {avg_loss:.4f}\")\n",
    "        \n",
    "        # Guardar checkpoint cada 'save_every' épocas\n",
    "        if (epoch + 1) % save_every == 0:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_loss,\n",
    "            }\n",
    "            checkpoint_path = f'modelos_guardados/checkpoint_epoch_{epoch+1}.pth'\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            print(f\"  ✓ Checkpoint guardado: {checkpoint_path}\")\n",
    "    \n",
    "    print(\"\\n✓ Entrenamiento completado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfb3d8f",
   "metadata": {},
   "source": [
    "Ejemplo de uso: entrenar el modelo guardando checkpoints cada 2 épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1270b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo: Entrenar guardando checkpoints cada 2 épocas\n",
    "# Nota: Este es un ejemplo, asegúrate de tener train_dataloader definido\n",
    "\n",
    "train_with_checkpoints(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=10,\n",
    "    device=device,\n",
    "    save_every=2  # Guardar cada 2 épocas\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b75070",
   "metadata": {},
   "source": [
    "### 7.4 Cargar un checkpoint para reanudar entrenamiento\n",
    "\n",
    "Si el entrenamiento se interrumpe, puedes cargar el último checkpoint y continuar desde donde lo dejaste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd9e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar un checkpoint guardado\n",
    "def load_checkpoint(model, optimizer, checkpoint_path):\n",
    "    \"\"\"\n",
    "    Carga un checkpoint y restaura el estado del modelo y optimizador\n",
    "    \n",
    "    Returns:\n",
    "        epoch: La época desde donde se continúa\n",
    "        loss: El loss del checkpoint\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    \n",
    "    print(f\"✓ Checkpoint cargado desde época {epoch}\")\n",
    "    print(f\"  Loss anterior: {loss:.4f}\")\n",
    "    \n",
    "    return epoch, loss\n",
    "\n",
    "# Ejemplo de uso:\n",
    "start_epoch, last_loss = load_checkpoint(model, optimizer, 'modelos_guardados/checkpoint_epoch_6.pth')\n",
    "# Ahora puedes continuar el entrenamiento desde start_epoch + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4515e2d1",
   "metadata": {},
   "source": [
    "### 7.5 Mejores prácticas\n",
    "\n",
    "**Consejos para guardar modelos:**\n",
    "\n",
    "1. **Guardar el mejor modelo**: Además de guardar checkpoints periódicos, guarda el modelo con el mejor desempeño (menor loss de validación o mejor accuracy)\n",
    "\n",
    "2. **Nombrar archivos claramente**: Usa nombres descriptivos como `modelo_epoch_10_loss_0.25.pth`\n",
    "\n",
    "3. **Limpiar checkpoints antiguos**: Para ahorrar espacio, puedes mantener solo los últimos N checkpoints\n",
    "\n",
    "4. **Guardar en diferentes formatos**: \n",
    "   - `.pth` o `.pt`: formato estándar de PyTorch\n",
    "   - También puedes guardar metadatos adicionales como hiperparámetros del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f356e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo: Guardar el mejor modelo durante el entrenamiento\n",
    "best_loss = float('inf')\n",
    "best_model_path = 'modelos_guardados/mejor_modelo.pth'\n",
    "\n",
    "# Durante el entrenamiento (dentro del loop de épocas):\n",
    "# if current_loss < best_loss:\n",
    "#     best_loss = current_loss\n",
    "#     torch.save({\n",
    "#         'epoch': epoch,\n",
    "#         'model_state_dict': model.state_dict(),\n",
    "#         'optimizer_state_dict': optimizer.state_dict(),\n",
    "#         'loss': best_loss,\n",
    "#     }, best_model_path)\n",
    "#     print(f\"  ✓ Nuevo mejor modelo guardado! Loss: {best_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
